#!/usr/bin/python

import os
import sys
import json
import time
import optparse
import ConfigParser

import rrdtool
import htcondor
from functions import parseArgs
from functions import dropObj
from functions import updateRrd
from functions import getFromURL
from functions import querySchedd
from functions import validateInt


GSTARTUP = int(time.time())


def analyzeScheddOutput(ad, workflows, taskInfo):
    jobs = querySchedd(ad, "WMAgent_RequestName isnt null && WMAgent_SubTaskName isnt null && JobPrio isnt null && DESIRED_Sites isnt null",
                       ["WMAgent_RequestName", "WMAgent_SubTaskName", "DESIRED_Sites", "MATCH_EXP_JOBGLIDEIN_CMSSite",
                        "JobPrio", "JobStatus", "RequestMemory", "MaxWallTimeMins"])
    for job in jobs:
        request = job['WMAgent_RequestName']
        subTask = job['WMAgent_SubTaskName'].split("/")[-1]
        desiredSites = job['DESIRED_Sites'].split(",")
        desiredSites = tuple(desiredSites.sort())
        runningSite = job.get("MATCH_EXP_JOBGLIDEIN_CMSSite")
        if job["JobStatus"] == 1:
            status = "MatchingIdle"
        elif job["JobStatus"] == 2:
            status = "Running"
        else:
            continue
        prio = job["JobPrio"]
        requestDict = workflows.setdefault(request, {})
        subtaskDict = requestDict.setdefault(subTask, {})
        summaryDict = subtaskDict.setdefault('Summary', {})
        summaryInternal = summaryDict.setdefault("Internal", {})

        mainTaskInfo = taskInfo.setdefault(request, {})
        mainSubTask = mainTaskInfo.setdefault(subTask, {})
        memory = 0 if 'RequestMemory' not in job.keys() else validateInt(job['RequestMemory'])
        walltime = 0 if 'MaxWallTimeMins' not in job.keys() else validateInt(job['MaxWallTimeMins'])
        key = "||".join(str(memory), str(walltime), str(job['DESIRED_Sites']), ad['Name'])
        mainSubTaskdebug = mainSubTask.setdefault(key, {"Idle": 0, "Running": 0, "DesiredSites": '', 'WallTime': walltime, 'Memory': memory, 'Schedd': ''})
        mainSubTaskdebug['Schedd'] = ad['Name']
        mainSubTaskdebug['Memory'] = memory
        mainSubTaskdebug['WallTime'] = walltime
        mainSubTaskdebug['DesiredSites'] = job['DESIRED_Sites']
        if job['JobStatus'] == 2:
            mainSubTaskdebug['Running'] += 1
        else:
            mainSubTaskdebug['Idle'] += 1

        jobinfo = (prio, desiredSites)
        if not runningSite:
            summaryInternal.setdefault(jobinfo, 0)
            summaryInternal[jobinfo] += 1
            for site in desiredSites:
                siteDict = subtaskDict.setdefault(site, {})
                prioDict = siteDict.setdefault(prio, {"Running": 0, "MatchingIdle": 0})
                prioDict.setdefault(status, 0)
                if status != "Running":
                    prioDict[status] += 1
        if runningSite:
            siteDict = subtaskDict.setdefault(runningSite, {})
            prioDict = siteDict.setdefault(prio, {"Running": 0, "MatchingIdle": 0})
            prioDict.setdefault(status, 0)
            prioDict[status] += 1


def analyze_prios_inner(workflows, sites, prio):
    """ Analyze priorities and this gives view of lower/higher running """
    # TODO: IMPROVE IT!!!!!
    # This analyze prios takes too much time to complete
    # when a lot of load is from production.
    # Need to take a look where to improve this.
    return 0, 0
#    higher_idle = 0
#    lower_running = 0
#    sites = set(sites)
#    if not sites:
#        return 0, 0
#    for request, request_dict in workflows.items():
#        for subtask, subtask_dict in request_dict.items():
#            for running_site, site_dict in subtask_dict.items():
#                if running_site == "Summary" and site_dict.get("Internal"):
#                    for jobinfo, jobs in site_dict["Internal"].items():
#                        idle_prio, desired_sites = jobinfo
#                        desired_sites = set(desired_sites)
#                        if (sites.intersection(desired_sites)) and idle_prio > prio:
#                            higher_idle += jobs
#                elif running_site in sites:
#                    for running_prio, prio_dict in site_dict.items():
#                        if running_prio >= prio:
#                            continue
#                        for status, count in prio_dict.items():
#                            if status != "Running":
#                                continue
#                            lower_running += count
#    return higher_idle, lower_running


def analyze_prios(workflows):
    for dummyrequest, requestDict in workflows.items():
        for dummysubtask, subtaskDict in requestDict.items():
            for site, siteDict in subtaskDict.items():
                if site == "Summary":
                    continue
                for dummyprio, prioDict in siteDict.items():
                    higherIdle, lowerRunning = 0, 0  # analyze_prios_inner(workflows, [site], prio)
                    prioDict["LowerPrioRunning"] = lowerRunning
                    prioDict["HigherPrioIdle"] = higherIdle


def summarize(workflows, gsites, tasks):
    for request, request_dict in workflows.items():
        for subtask, subtask_dict in request_dict.items():
            min_prio = min([min(site_dict.keys()) for site_dict in subtask_dict.values()])
            sites = subtask_dict.keys()
            taskinfo = tasks.get(request, {}).get(subtask, {})
            higher_idle, lower_running = analyze_prios_inner(workflows, sites, min_prio)
            idle = sum(subtask_dict.get("Summary", {}).get("Internal", {}).values())
            running = 0
            for site_dict in subtask_dict.values():
                for prio_dict in site_dict.values():
                    running += prio_dict.get("Running", 0)
            subtask_dict["Summary"].update({"BasePrio": min_prio, "Running": running, "Idle": idle, "HigherPrioIdle": higher_idle, "LowerPrioRunning": lower_running, "TaskInfo": taskinfo})

        min_prio = int(min([float(subtask_dict["Summary"]["BasePrio"]) for subtask_dict in request_dict.values()]))
        min_prio = min_prio % 10000000
        sites = set()
        for subtask_dict in request_dict.values():
            for site, site_dict in subtask_dict.items():
                if min_prio in site_dict:
                    sites.add(site)
        running = sum([subtask_dict["Summary"]["Running"] for subtask_dict in request_dict.values()])
        idle = sum([subtask_dict["Summary"]["Idle"] for subtask_dict in request_dict.values()])
        higher_idle, lower_running = analyze_prios_inner(workflows, sites, min_prio)
        request_dict["Summary"] = {"BasePrio": min_prio, "Running": running, "Idle": idle, "HigherPrioIdle": higher_idle, "LowerPrioRunning": lower_running}

        request_sites = request_dict["Summary"].setdefault("Sites", {})
        for subtask, subtask_dict in request_dict.items():
            if subtask == "Summary":
                continue
            for site, site_dict in subtask_dict.items():
                if site == "Summary":
                    continue
                request_sites.setdefault(site, {"Running": 0, "MatchingIdle": 0})
                request_sites[site]["Running"] += sum([prio_dict["Running"] for prio_dict in site_dict.values()])
                request_sites[site]["MatchingIdle"] += sum([prio_dict["MatchingIdle"] for prio_dict in site_dict.values()])

        for site, site_dict in request_sites.items():
            gsites_dict = gsites.setdefault(site, {})
            gsites_dict.setdefault(request, {"Running": 0, "MatchingIdle": 0, "BasePrio": min_prio, 'MatchingSites': len(request_sites)})
            for status, count in site_dict.items():
                gsites_dict[request][status] += site_dict[status]


def drop_obj(obj, dirname, fname):
    if not os.path.exists(dirname):
        os.makedirs(dirname)
    fname_tmp = os.path.join(dirname, fname + ".tmp")
    fname = os.path.join(dirname, fname)
    json.dump(obj, open(fname_tmp, "w"))
    os.rename(fname_tmp, fname)


def write_json(workflows, gsites, output):

    sites = {}
    running = 0
    idle = 0
    for request_dict in workflows.values():
        for site, site_dict in request_dict["Summary"]["Sites"].items():
            sites.setdefault(site, {"Running": 0, "MatchingIdle": 0, "RequestCount": 0})
            sites[site]["Running"] += site_dict["Running"]
            sites[site]["MatchingIdle"] += site_dict["MatchingIdle"]
            sites[site]["RequestCount"] += 1
        running += request_dict["Summary"]["Running"]
        idle += request_dict["Summary"]["Idle"]
    requests = len(workflows)

    now = int(time.time())

    drop_obj(sites, output, "site_summary.json")
    drop_obj({"Running": running, "Idle": idle, "RequestCount": requests, "UpdateTime": now}, output, "totals.json")

    for site, site_dict in gsites.items():
        site_dir = os.path.join(output, site)
        final_obj = dict(sites[site])
        final_obj["UpdateTime"] = now
        drop_obj(final_obj, site_dir, "totals.json")
        drop_obj(site_dict, site_dir, "summary.json")

    final_obj = {}
    for request, request_dict in workflows.items():
        final_obj[request] = dict(request_dict["Summary"])
        final_obj[request]["SiteCount"] = len(final_obj[request]["Sites"])
        del final_obj[request]["Sites"]
        request_summary = dict(final_obj[request])
        request_summary['UpdateTime'] = now
        request_summary['SubtaskCount'] = len(request_dict)-1
        drop_obj(request_summary, os.path.join(output, request), "totals.json")
    drop_obj(final_obj, output, "summary.json")

    for request, request_dict in workflows.items():
        final_obj = {}
        request_sites = {}
        for subtask, subtask_dict in request_dict.items():
            if subtask == "Summary":
                continue
            final_obj[subtask] = subtask_dict["Summary"]
            sites = subtask_dict.keys()
            sites.remove("Summary")
            #final_obj["SiteCount"] = len(sites)

            sites = {}
            for site, site_dict in subtask_dict.items():
                if site == "Summary":
                    continue
                sites[site] = {"Running":      sum(prio_dict["Running"] for prio_dict in site_dict.values()),
                               "MatchingIdle": sum(prio_dict["MatchingIdle"] for prio_dict in site_dict.values())}
            subtask_dir = os.path.join(output, request, subtask)
            drop_obj(sites, subtask_dir, "site_summary.json")
            for site, site_dict in sites.items():
                request_sites.setdefault(site, {"Running": 0, "MatchingIdle": 0})
                for status, count in site_dict.items():
                    request_sites[site][status] += count
            subtask_dict["Summary"]["SiteCount"] = len(sites)
            out = subtask_dict["Summary"]
            out["Internal"] = {}
            out["Sites"] = sites.keys()
            drop_obj(out, subtask_dir, "summary.json")
        request_dir = os.path.join(output, request)
        drop_obj(request_sites, request_dir, "site_summary.json")
        drop_obj(final_obj, request_dir, "summary.json")


def write_rrds(workflows, gsites, output):

    sites = {}
    running = 0
    idle = 0
    for request_dict in workflows.values():
        for site, site_dict in request_dict["Summary"]["Sites"].items():
            sites.setdefault(site, {"Running": 0, "MatchingIdle": 0})
            sites[site]["Running"] += site_dict["Running"]
            sites[site]["MatchingIdle"] += site_dict["MatchingIdle"]
        running += request_dict["Summary"]["Running"]
        idle += request_dict["Summary"]["Idle"]
    fname = os.path.join(output, "summary.rrd")
    if not os.path.exists(fname):
        rrdtool.create(fname,
            "--step", "180",
            "DS:Running:GAUGE:360:U:U",
            "DS:Idle:GAUGE:360:U:U",
            "RRA:AVERAGE:0.5:1:1000",
            "RRA:AVERAGE:0.5:20:2000",
        )
    update_rrd(fname, "%d:%d:%d" % (GSTARTUP, running, idle))
    for site, site_dict in sites.items():
        fname = os.path.join(output, "%s.rrd" % site)
        if not os.path.exists(fname):
            rrdtool.create(fname,
                "--step", "180",
                "DS:Running:GAUGE:360:U:U",
                "DS:MatchingIdle:GAUGE:360:U:U",
                "RRA:AVERAGE:0.5:1:1000",
                "RRA:AVERAGE:0.5:20:2000",
            )   
        update_rrd(fname, "%d:%d:%d" % (GSTARTUP, site_dict["Running"], site_dict["MatchingIdle"]))

    for site, site_dict in gsites.items():
        site_dir = os.path.join(output, site)
        for request, request_dict in site_dict.items():
            fname = os.path.join(site_dir, "%s.rrd" % request)
            if not os.path.exists(fname):
                rrdtool.create(fname,
                    "--step", "180",
                    "DS:Running:GAUGE:360:U:U",
                    "DS:MatchingIdle:GAUGE:360:U:U",
                    "RRA:AVERAGE:0.5:1:1000",
                    "RRA:AVERAGE:0.5:20:2000",
                )
            update_rrd(fname, "%d:%d:%d" % (GSTARTUP, request_dict["Running"], request_dict["MatchingIdle"]))

    for request, request_dict in workflows.items():
        request_dir = os.path.join(output, request)
        if not os.path.exists(request_dir):
            os.makedirs(request_dir)
        fname = os.path.join(request_dir, "request.rrd")
        if not os.path.exists(fname):
            rrdtool.create(fname,
                "--step", "180",
                "DS:Running:GAUGE:360:U:U",
                "DS:Idle:GAUGE:360:U:U",
                "DS:HigherPrioIdle:GAUGE:360:U:U",
                "DS:LowerPrioRunning:GAUGE:360:U:U",
                "RRA:AVERAGE:0.5:1:1000",
                "RRA:AVERAGE:0.5:20:2000",
                )
        stats = request_dict["Summary"]["Running"], request_dict["Summary"]["Idle"], request_dict["Summary"]["HigherPrioIdle"], request_dict["Summary"]["LowerPrioRunning"]
        update_rrd(fname, (("%d:" % GSTARTUP) + ":".join(["%d"]*len(stats))) % stats)

        for site, site_dict in request_dict["Summary"]["Sites"].items():
            fname = os.path.join(request_dir, "%s.rrd" % site)
            if not os.path.exists(fname):
                rrdtool.create(fname,
                    "--step", "180",
                    "DS:Running:GAUGE:360:U:U",
                    "DS:MatchingIdle:GAUGE:360:U:U",
                    "RRA:AVERAGE:0.5:1:1000",
                    "RRA:AVERAGE:0.5:20:2000",
                )
            update_rrd(fname, "%d:%d:%d" % (GSTARTUP, site_dict["Running"], site_dict["MatchingIdle"]))

        for subtask, subtask_dict in request_dict.items():
            if subtask == "Summary":
                continue
            subtask_dir = os.path.join(request_dir, subtask)
            if not os.path.exists(subtask_dir):
                os.makedirs(subtask_dir)
            fname = os.path.join(subtask_dir, "subtask.rrd")
            if not os.path.exists(fname):
                rrdtool.create(fname,
                    "--step", "180",
                    "DS:Running:GAUGE:360:U:U",
                    "DS:Idle:GAUGE:360:U:U",
                    "DS:HigherPrioIdle:GAUGE:360:U:U",
                    "DS:LowerPrioRunning:GAUGE:360:U:U",
                    "RRA:AVERAGE:0.5:1:1000",   
                    "RRA:AVERAGE:0.5:20:2000",
                    )
            stats = subtask_dict["Summary"]["Running"], subtask_dict["Summary"]["Idle"], subtask_dict["Summary"]["HigherPrioIdle"], subtask_dict["Summary"]["LowerPrioRunning"]
            update_rrd(fname, (("%d:" % GSTARTUP) + ":".join(["%d"]*len(stats))) % stats)

            for site, site_dict in subtask_dict.items():
                if site == "Summary":
                    continue
                fname = os.path.join(subtask_dir, "%s.rrd" % site)
                if not os.path.exists(fname):
                    rrdtool.create(fname,
                        "--step", "180",
                        "DS:Running:GAUGE:360:U:U",
                        "DS:MatchingIdle:GAUGE:360:U:U",
                        "DS:HigherPrioIdle:GAUGE:360:U:U",
                        "DS:LowerPrioRunning:GAUGE:360:U:U",
                        "RRA:AVERAGE:0.5:1:1000",
                        "RRA:AVERAGE:0.5:20:2000",
                        )
                stats = sum(prio_dict["Running"] for prio_dict in site_dict.values()), \
                        sum(prio_dict["MatchingIdle"] for prio_dict in site_dict.values()), \
                        sum(prio_dict["HigherPrioIdle"] for prio_dict in site_dict.values()), \
                        sum(prio_dict["LowerPrioRunning"] for prio_dict in site_dict.values())
                update_rrd(fname, (("%d:" % GSTARTUP) + ":".join(["%d"]*len(stats))) % stats)


def main():
    opts, args = parse_args()

    if opts.pool:
        coll = htcondor.Collector(opts.pool)
    else:
        coll = htcondor.Collector()

    schedd_ads = coll.query(htcondor.AdTypes.Schedd, 'CMSGWMS_Type=?="prodschedd"', ['Name', 'MyAddress', 'ScheddIpAddr'])

    sites = {}
    workflows = {}
    taskInfo = {}
    for ad in schedd_ads:
        print "Querying schedd", ad['Name']
        analyzeScheddOutput(ad, workflows, taskInfo)

    analyze_prios(workflows)
    summarize(workflows, sites, taskInfo)

    if opts.output:
        write_json(workflows, sites, opts.output)
        write_rrds(workflows, sites, opts.output)

if __name__ == "__main__":
    main()

